{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSarsaFunction():\n",
    "    def __init__(self, n_features, action_space = 4, weights=None, default=0.0, lr = 0.001, gamma = 0.99, epsilon = 0.91, annealing_coefficient = 0.99999999):\n",
    "        #In this case, features represents the states the agent see\n",
    "        #n_features should be the number of states that the agent sees\n",
    "        #action_space should be the number of actions the agent can take\n",
    "\n",
    "        self.n_features = n_features\n",
    "        self.action_space = action_space\n",
    "        self.lr = lr #learning rate\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.annealing_coefficient = annealing_coefficient\n",
    "\n",
    "        if weights == None:\n",
    "            self.weights = np.array(\n",
    "                [\n",
    "                    [default] * self.action_space\n",
    "                    for _ in range(0, n_features)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def update(self, curent_stacked_feature, action, next_stacked_features, reward, done, possible_next_actions):\n",
    "        # update the weights\n",
    "        q = 0\n",
    "        for i in range(len(self.weights)):\n",
    "            q += self.weights[i][action] * curent_stacked_feature[i]\n",
    "\n",
    "        q_next = 0\n",
    "        next_action = self.take_action(possible_next_actions, next_stacked_features)\n",
    "        for i in range(len(next_stacked_features)):\n",
    "            q_next += self.weights[i][next_action] * next_stacked_features[i]\n",
    "    \n",
    "      \n",
    "        #for stack in self.weights:\n",
    "        td_error = reward + self.gamma * q_next * (1-done) - q\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i][action] += self.lr * td_error * curent_stacked_feature[i]\n",
    "\n",
    "        #annealing epsilon\n",
    "        if self.epsilon > 0.1:\n",
    "            self.epsilon *= self.annealing_coefficient\n",
    "    \n",
    "    def take_action(self, possible_actions, curent_stacked_feature):\n",
    "        if(np.random.random()  < self.epsilon):\n",
    "            return np.random.choice(possible_actions)\n",
    "        else:\n",
    "            q = np.zeros(len(possible_actions))\n",
    "            for i in range(len(curent_stacked_feature)):\n",
    "                for j in range(len(possible_actions)):\n",
    "                    q[j] += np.dot( self.weights[i][possible_actions[j]], curent_stacked_feature[i])\n",
    "\n",
    "            arg_max_index = np.argmax(q)\n",
    "            return possible_actions[arg_max_index]\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
